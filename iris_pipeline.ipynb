{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3c941ef-4344-48e9-a6b7-57f86c5564bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Vertex SDK for Python\n",
    "! pip3 install --upgrade --quiet  google-cloud-aiplatform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7e342cb-39cd-474f-929d-9ffb552127e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BUCKET_URI= f\"gs://sanguine-fx-461507-k2\" #@param {type:\"string\"} custom\n",
    "PROJECT_ID = \"sanguine-fx-461507-k2\"  # id from my first project \n",
    "LOCATION = \"us-central1\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d65c4352-960f-4eed-8da5-7f53ce3bbc91",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating gs://sanguine-fx-461507-k2/...\n",
      "ServiceException: 409 A Cloud Storage bucket named 'sanguine-fx-461507-k2' already exists. Try another name. Bucket names must be globally unique across all Google Cloud projects, including those outside of your organization.\n"
     ]
    }
   ],
   "source": [
    "! gsutil mb -l {LOCATION} -p {PROJECT_ID} {BUCKET_URI}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27532afd-ecd7-4a09-b533-ee7a61d49a06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "\n",
    "aiplatform.init(project=PROJECT_ID, location=LOCATION, staging_bucket=BUCKET_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55bc84b9-eedc-4f35-a6fd-bc1b6a66bd03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# MODEL_ARTIFACT_DIR = \"my-models/iris-classifier-week-3\"  # @param {type:\"string\"}\n",
    "# REPOSITORY = \"iris-classifier-repo\"  # @param {type:\"string\"}\n",
    "# IMAGE = \"iris-classifier-img\"  # @param {type:\"string\"}\n",
    "# MODEL_DISPLAY_NAME = \"iris-classifier\"  # @param {type:\"string\"}\n",
    "# BIGQUERY_DATASET_NAME=\"iris_classifier_tutorial\" #@param {type:\"string\"} custom\n",
    "# AI_PLATFORM_MODEL_NAME=\"iris_classifier_jsd_model\" #@param {type:\"string\"\n",
    "\n",
    "# # Set the defaults if no names were specified\n",
    "# if MODEL_ARTIFACT_DIR == \"[your-artifact-directory]\":\n",
    "#     MODEL_ARTIFACT_DIR = \"custom-container-prediction-model\"\n",
    "\n",
    "# if REPOSITORY == \"[your-repository-name]\":\n",
    "#     REPOSITORY = \"custom-container-prediction\"\n",
    "\n",
    "# if IMAGE == \"[your-image-name]\":\n",
    "#     IMAGE = \"sklearn-fastapi-server\"\n",
    "\n",
    "# if MODEL_DISPLAY_NAME == \"[your-model-display-name]\":\n",
    "#     MODEL_DISPLAY_NAME = \"sklearn-custom-container\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43657cb6-3ec2-4c7d-af7d-86490a7b4de1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "100d532f-8567-4c59-a00b-b47af84b8e55",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "      <th>sample_id</th>\n",
       "      <th>event_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-07-12 17:01:29.358944+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-07-17 17:01:29.359349+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>2</td>\n",
       "      <td>2025-07-04 17:01:29.359459+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>3</td>\n",
       "      <td>2025-07-15 17:01:29.359542+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>4</td>\n",
       "      <td>2025-07-12 17:01:29.359631+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "      <td>145</td>\n",
       "      <td>2025-07-01 17:01:29.376121+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>virginica</td>\n",
       "      <td>146</td>\n",
       "      <td>2025-07-18 17:01:29.376288+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>virginica</td>\n",
       "      <td>147</td>\n",
       "      <td>2025-06-21 17:01:29.376474+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "      <td>148</td>\n",
       "      <td>2025-07-18 17:01:29.376627+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "      <td>149</td>\n",
       "      <td>2025-07-06 17:01:29.376770+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width    species  \\\n",
       "0             5.1          3.5           1.4          0.2     setosa   \n",
       "1             4.9          3.0           1.4          0.2     setosa   \n",
       "2             4.7          3.2           1.3          0.2     setosa   \n",
       "3             4.6          3.1           1.5          0.2     setosa   \n",
       "4             5.0          3.6           1.4          0.2     setosa   \n",
       "..            ...          ...           ...          ...        ...   \n",
       "145           6.7          3.0           5.2          2.3  virginica   \n",
       "146           6.3          2.5           5.0          1.9  virginica   \n",
       "147           6.5          3.0           5.2          2.0  virginica   \n",
       "148           6.2          3.4           5.4          2.3  virginica   \n",
       "149           5.9          3.0           5.1          1.8  virginica   \n",
       "\n",
       "     sample_id                   event_timestamp  \n",
       "0            0  2025-07-12 17:01:29.358944+00:00  \n",
       "1            1  2025-07-17 17:01:29.359349+00:00  \n",
       "2            2  2025-07-04 17:01:29.359459+00:00  \n",
       "3            3  2025-07-15 17:01:29.359542+00:00  \n",
       "4            4  2025-07-12 17:01:29.359631+00:00  \n",
       "..         ...                               ...  \n",
       "145        145  2025-07-01 17:01:29.376121+00:00  \n",
       "146        146  2025-07-18 17:01:29.376288+00:00  \n",
       "147        147  2025-06-21 17:01:29.376474+00:00  \n",
       "148        148  2025-07-18 17:01:29.376627+00:00  \n",
       "149        149  2025-07-06 17:01:29.376770+00:00  \n",
       "\n",
       "[150 rows x 7 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/iris.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dafa7ee6-298b-4199-8603-81dd5e6cb8c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## create github repo without readme\n",
    "# ! git init\n",
    "# ! git branch -M main\n",
    "# ! git remote add origin https://github.com/surupi/MLOps-Practice.git\n",
    "# ! git add data/\n",
    "# ! git config --global user.email \"surupi.nandi@gmail.com\"\n",
    "# ! git config --global user.name \"surupi\"\n",
    "# ! git commit -m \"Uploaded original iris data\"\n",
    "# ! git push origin main\n",
    "## token = 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\n",
    "# ! git checkout -b dev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52d34e0-9687-49c4-ad26-49f6edb83efc",
   "metadata": {},
   "source": [
    "## Modifying dataset to upload in bigquery source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b6f9cc7-8fd9-4b74-b439-59bc5eae35cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "\n",
    "df = data.copy()\n",
    "\n",
    "# Add entity and timestamp\n",
    "df[\"sample_id\"] = df.index\n",
    "df[\"event_timestamp\"] = [\n",
    "    pd.to_datetime(datetime.utcnow() - timedelta(days=random.randint(0, 30)), utc=True)\n",
    "    for _ in range(len(df))\n",
    "]\n",
    "\n",
    "data['sample_id'] = data.index\n",
    "data['event_timestamp'] = df['event_timestamp']\n",
    "\n",
    "data.to_csv('data/iris.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57015c13-dff1-42dd-b119-0a5ad83e172d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create big query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e89d5a16-1cec-46b8-ae8a-a7bc5b344f23",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 150 rows to sanguine-fx-461507-k2.irisPractice.features_table\n"
     ]
    }
   ],
   "source": [
    "# donot run this more that once \n",
    "from google.cloud import bigquery\n",
    "\n",
    "project_id = PROJECT_ID  # replace this\n",
    "dataset_id = \"irisPractice\"      # name of the bigquery\n",
    "table_id = f\"{project_id}.{dataset_id}.features_table\"\n",
    "\n",
    "client = bigquery.Client(project=project_id)\n",
    "\n",
    "# Upload to BigQuery\n",
    "job = client.load_table_from_dataframe(df, table_id)\n",
    "job.result()\n",
    "\n",
    "print(f\"Uploaded {len(df)} rows to {table_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48c8f999-e671-4339-be49-d86dbac34c63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if the above code is run once, then run this\n",
    "project_id = PROJECT_ID  # replace this\n",
    "dataset_id = \"irisPractice\"      # name of the bigquery\n",
    "table_id = f\"{project_id}.{dataset_id}.features_table\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ce93d0-3bd2-4e11-a516-2153776585e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install feast[gcp]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4de8593-dba9-4ad2-8b7d-62678b229b9c",
   "metadata": {},
   "source": [
    "## Introducing feast feature store"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e9298e-c857-430e-96fa-84dfe15c3e2e",
   "metadata": {
    "tags": []
   },
   "source": [
    "! pip install feast[gcp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1bdb920e-57a8-429f-9d58-f689797ae414",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n",
      "/home/jupyter/feast-store/feature_schema.py:6: DeprecationWarning: Entity value_type will be mandatory in the next release. Please specify a value_type for entity 'sample_id'.\n",
      "  sample = Entity(name=\"sample_id\", join_keys=[\"sample_id\"])\n",
      "No project found in the repository. Using project name common_iris defined in feature_store.yaml\n",
      "Applying changes for project common_iris\n",
      "Deploying infrastructure for \u001b[1m\u001b[32miris_features\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! cd feast-store/ && feast apply"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41516d5a-bee3-410f-920b-a8a5b39550b1",
   "metadata": {},
   "source": [
    "## Introducing Hyperopt for Hyperparameter tuning with MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1c225217-80ef-42d3-852e-97ed24cf1aa1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# screen -S \"mlflow_execution\"\n",
    "# pip install mlflow\n",
    "# mlflow server --host 0.0.0.0 --port 8100\n",
    "# crlt+a+d = to run in detached mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a463353b-9919-4a55-bd53-6813aca57579",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<Experiment: artifact_location='mlflow-artifacts:/0', creation_time=1752859324391, experiment_id='0', last_update_time=1752859324391, lifecycle_stage='active', name='Default', tags={}>]\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "from mlflow import MlflowClient\n",
    "from mlflow.models import infer_signature\n",
    "from pprint import pprint\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:8100\")\n",
    "client = MlflowClient(mlflow.get_tracking_uri())\n",
    "all_experiments = client.search_experiments()\n",
    "print(all_experiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f8295cc4-1a8c-480c-9b7d-3ba9717db20a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/18 17:35:00 INFO mlflow.tracking.fluent: Experiment with name 'IRIS practice classifier: Mlflow Practice' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/602550827807625800', creation_time=1752860100730, experiment_id='602550827807625800', last_update_time=1752860100730, lifecycle_stage='active', name='IRIS practice classifier: Mlflow Practice', tags={}>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting experiment name for mlflow\n",
    "\n",
    "mlflow.set_experiment(\"IRIS practice classifier: Mlflow Practice\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e976cc0c-67c8-442e-aa77-140d286ee27d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting hyperopt\n",
      "  Downloading hyperopt-0.2.7-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from hyperopt) (2.1.3)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from hyperopt) (1.15.3)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from hyperopt) (1.17.0)\n",
      "Requirement already satisfied: networkx>=2.2 in /opt/conda/lib/python3.10/site-packages (from hyperopt) (3.4.2)\n",
      "Collecting future (from hyperopt)\n",
      "  Downloading future-1.0.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from hyperopt) (4.67.1)\n",
      "Requirement already satisfied: cloudpickle in /opt/conda/lib/python3.10/site-packages (from hyperopt) (3.1.1)\n",
      "Collecting py4j (from hyperopt)\n",
      "  Downloading py4j-0.10.9.9-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Downloading hyperopt-0.2.7-py2.py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading future-1.0.0-py3-none-any.whl (491 kB)\n",
      "Downloading py4j-0.10.9.9-py2.py3-none-any.whl (203 kB)\n",
      "Installing collected packages: py4j, future, hyperopt\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3/3\u001b[0m [hyperopt]2/3\u001b[0m [hyperopt]\n",
      "\u001b[1A\u001b[2KSuccessfully installed future-1.0.0 hyperopt-0.2.7 py4j-0.10.9.9\n"
     ]
    }
   ],
   "source": [
    "! pip install hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3c0f4d85-5079-494a-9376-07f5f719b219",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from hyperopt import fmin, tpe, hp, Trials, STATUS_OK\n",
    "\n",
    "# Define hyperparameter search space\n",
    "space = {\n",
    "    'criterion': hp.choice('criterion', ['gini', 'entropy']),\n",
    "    'max_depth': hp.quniform('max_depth', 1, 10, 1),\n",
    "    'min_samples_split': hp.quniform('min_samples_split', 2, 10, 1),\n",
    "    'min_samples_leaf': hp.quniform('min_samples_leaf', 1, 5, 1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "14eb4faa-ffc3-40c4-8405-7ecbe4a2fa0c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Feature schema -----\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 7 columns):\n",
      " #   Column           Non-Null Count  Dtype              \n",
      "---  ------           --------------  -----              \n",
      " 0   species          150 non-null    object             \n",
      " 1   sample_id        150 non-null    int64              \n",
      " 2   event_timestamp  150 non-null    datetime64[us, UTC]\n",
      " 3   sepal_length     65 non-null     float64            \n",
      " 4   petal_length     65 non-null     float64            \n",
      " 5   sepal_width      65 non-null     float64            \n",
      " 6   petal_width      65 non-null     float64            \n",
      "dtypes: datetime64[us, UTC](1), float64(4), int64(1), object(1)\n",
      "memory usage: 8.3+ KB\n",
      "None\n",
      "\n",
      "----- Example features -----\n",
      "\n",
      "  species  sample_id                  event_timestamp  sepal_length  \\\n",
      "0  setosa         46 2025-07-07 17:34:07.234564+00:00           NaN   \n",
      "1  setosa         15 2025-06-21 17:34:07.232267+00:00           NaN   \n",
      "2  setosa         16 2025-06-25 17:34:07.232340+00:00           NaN   \n",
      "3  setosa         40 2025-07-10 17:34:07.234108+00:00           NaN   \n",
      "4  setosa          4 2025-07-11 17:34:07.231411+00:00           NaN   \n",
      "\n",
      "   petal_length  sepal_width  petal_width  \n",
      "0           NaN          NaN          NaN  \n",
      "1           NaN          NaN          NaN  \n",
      "2           NaN          NaN          NaN  \n",
      "3           NaN          NaN          NaN  \n",
      "4           NaN          NaN          NaN  \n",
      "   sample_id  sepal_length  petal_length  sepal_width  petal_width\n",
      "0         46           NaN           NaN          NaN          NaN\n",
      "1         15           NaN           NaN          NaN          NaN\n",
      "2         16           NaN           NaN          NaN          NaN\n",
      "3         40           NaN           NaN          NaN          NaN\n",
      "4          4           NaN           NaN          NaN          NaN\n",
      "0    setosa\n",
      "1    setosa\n",
      "2    setosa\n",
      "3    setosa\n",
      "4    setosa\n",
      "Name: species, dtype: object\n",
      "120 120\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['artifacts/model.joblib']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import feast\n",
    "from joblib import dump\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Load Iris entity dataframe (with sample_id and event_timestamp)\n",
    "iris_df = pd.read_csv(\"data/iris.csv\", sep=\",\")\n",
    "iris_df[\"event_timestamp\"] = pd.to_datetime(iris_df[\"event_timestamp\"])\n",
    "iris_df = iris_df.drop(columns=['sepal_length', 'sepal_width', 'petal_width', 'petal_length'])\n",
    "\n",
    "# Connect to feature store\n",
    "fs = feast.FeatureStore(repo_path=\"feast-store/\")\n",
    "\n",
    "# Load features from BigQuery (via Feast)\n",
    "training_df = fs.get_historical_features(\n",
    "    entity_df=iris_df,\n",
    "    features=[\n",
    "        \"iris_features:sepal_length\",\n",
    "        \"iris_features:petal_length\",\n",
    "        \"iris_features:sepal_width\",\n",
    "        \"iris_features:petal_width\"\n",
    "    ],\n",
    ").to_df()\n",
    "\n",
    "print(\"----- Feature schema -----\\n\")\n",
    "print(training_df.info())\n",
    "\n",
    "print(\"\\n----- Example features -----\\n\")\n",
    "print(training_df.head())\n",
    "\n",
    "# Train model\n",
    "target = \"species\"\n",
    "\n",
    "train_X = training_df.drop(columns=[target, 'event_timestamp'])[:120]\n",
    "print(train_X.head())\n",
    "train_Y = training_df.loc[:119, target]\n",
    "print(train_Y.head())\n",
    "print(len(train_X), len(train_Y))\n",
    "\n",
    "# model = LogisticRegression(max_iter=200)\n",
    "model = DecisionTreeClassifier(max_depth = 3, random_state = 1)\n",
    "model.fit(train_X[sorted(train_X.columns)], train_Y)\n",
    "\n",
    "# Save the model\n",
    "dump(model, \"artifacts/model.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5902a8c9-e0e4-4970-a9db-d9dca685c576",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from hyperopt import fmin, tpe, hp, Trials, STATUS_OK\n",
    "\n",
    "# # Define hyperparameter search space\n",
    "# space = {\n",
    "#     'criterion': hp.choice('criterion', ['gini', 'entropy']),\n",
    "#     'max_depth': hp.quniform('max_depth', 1, 10, 1),\n",
    "#     'min_samples_split': hp.quniform('min_samples_split', 2, 10, 1),\n",
    "#     'min_samples_leaf': hp.quniform('min_samples_leaf', 1, 5, 1)\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2d72e153-b499-4abc-85a7-ef4c167e34c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = data.drop(columns=['species', 'sample_id', 'event_timestamp'])\n",
    "Y = data['species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9b9eb793-c8ed-4dde-8369-93a20bff15ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_X, test_X, train_Y, test_Y = train_test_split(X, Y, test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f1bb2c72-b3eb-43e9-beda-942f50816097",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.plotting import parallel_coordinates\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn import metrics\n",
    "\n",
    "# Define the objective function\n",
    "def objective(params):\n",
    "    # Cast hyperparameters to int where required\n",
    "    params['max_depth'] = int(params['max_depth'])\n",
    "    params['min_samples_split'] = int(params['min_samples_split'])\n",
    "    params['min_samples_leaf'] = int(params['min_samples_leaf'])\n",
    "\n",
    "    with mlflow.start_run(nested=True):\n",
    "        \n",
    "        # Log hyperparameters\n",
    "        mlflow.log_params(params)\n",
    "\n",
    "        clf = DecisionTreeClassifier(**params, random_state=42)\n",
    "\n",
    "        clf.fit(train_X, train_Y)\n",
    "\n",
    "        y_pred = clf.predict(test_X)\n",
    "\n",
    "        # Calculate accuracy\n",
    "        accuracy = metrics.accuracy_score(test_Y, y_pred)\n",
    "\n",
    "        # Log metrics\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "\n",
    "        # Log tags\n",
    "        mlflow.set_tag(\"Training Info\", \"DecisionTreeClassifier for Iris Dataset\")\n",
    "\n",
    "        # Log model\n",
    "        mlflow.sklearn.log_model(clf, \"model\")        \n",
    "\n",
    "        return {'loss': 1 - accuracy, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e537b9bd-acaa-4ce7-bfed-9a6e507764cc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/18 17:38:17 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\n",
      "\u001b[31m2025/07/18 17:38:21 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run omniscient-duck-907 at: http://127.0.0.1:8100/#/experiments/602550827807625800/runs/76281a2be6b8418785a4e89ffeb0aa83\n",
      "\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:8100/#/experiments/602550827807625800\n",
      "\n",
      " 10%|â–ˆ         | 1/10 [00:03<00:35,  3.91s/trial, best loss: 0.08695652173913049]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/18 17:38:21 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\n",
      "\u001b[31m2025/07/18 17:38:25 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run sneaky-loon-837 at: http://127.0.0.1:8100/#/experiments/602550827807625800/runs/01e46a0f77ca46d18e164985f29b9b30\n",
      "\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:8100/#/experiments/602550827807625800    \n",
      "\n",
      " 20%|â–ˆâ–ˆ        | 2/10 [00:07<00:29,  3.64s/trial, best loss: 0.08695652173913049]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/18 17:38:25 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\n",
      "\u001b[31m2025/07/18 17:38:28 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run dashing-bee-863 at: http://127.0.0.1:8100/#/experiments/602550827807625800/runs/db6828185a504ca3ba84fc8f7f9c6654\n",
      "\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:8100/#/experiments/602550827807625800    \n",
      "\n",
      " 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:10<00:25,  3.62s/trial, best loss: 0.08695652173913049]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/18 17:38:28 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\n",
      "\u001b[31m2025/07/18 17:38:32 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run fun-goose-546 at: http://127.0.0.1:8100/#/experiments/602550827807625800/runs/67bfa3afdfcc4c4496368de28bb02629\n",
      "\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:8100/#/experiments/602550827807625800    \n",
      "\n",
      " 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:14<00:21,  3.58s/trial, best loss: 0.08695652173913049]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/18 17:38:32 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\n",
      "\u001b[31m2025/07/18 17:38:35 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run chill-chimp-881 at: http://127.0.0.1:8100/#/experiments/602550827807625800/runs/362c3e6784584f87a97af7bd3caefad2\n",
      "\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:8100/#/experiments/602550827807625800    \n",
      "\n",
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:18<00:17,  3.58s/trial, best loss: 0.08695652173913049]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/18 17:38:35 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\n",
      "\u001b[31m2025/07/18 17:38:39 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run honorable-horse-68 at: http://127.0.0.1:8100/#/experiments/602550827807625800/runs/877ef57784ae42e189dc8eab80cf6232\n",
      "\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:8100/#/experiments/602550827807625800    \n",
      "\n",
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:21<00:14,  3.54s/trial, best loss: 0.08695652173913049]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/18 17:38:39 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\n",
      "\u001b[31m2025/07/18 17:38:42 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run useful-pig-973 at: http://127.0.0.1:8100/#/experiments/602550827807625800/runs/9ed2238c701c4550b0cfd41cd6f5b484\n",
      "\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:8100/#/experiments/602550827807625800    \n",
      "\n",
      " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:24<00:10,  3.47s/trial, best loss: 0.08695652173913049]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/18 17:38:42 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\n",
      "\u001b[31m2025/07/18 17:38:45 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run debonair-cow-937 at: http://127.0.0.1:8100/#/experiments/602550827807625800/runs/ccb4cd8660344313bee0563002267bd3\n",
      "\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:8100/#/experiments/602550827807625800    \n",
      "\n",
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:28<00:06,  3.48s/trial, best loss: 0.08695652173913049]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/18 17:38:46 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\n",
      "\u001b[31m2025/07/18 17:38:49 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run vaunted-shark-988 at: http://127.0.0.1:8100/#/experiments/602550827807625800/runs/b406785e9aca4152bac3429a990224bb\n",
      "\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:8100/#/experiments/602550827807625800    \n",
      "\n",
      " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:31<00:03,  3.45s/trial, best loss: 0.08695652173913049]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/18 17:38:49 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\n",
      "\u001b[31m2025/07/18 17:38:52 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run charming-panda-68 at: http://127.0.0.1:8100/#/experiments/602550827807625800/runs/0ec0d7d13d7c4a2e8fc1c5211e7a095c\n",
      "\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:8100/#/experiments/602550827807625800    \n",
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:35<00:00,  3.51s/trial, best loss: 0.08695652173913049]\n",
      "Best hyperparameters: {'criterion': np.int64(0), 'max_depth': np.float64(9.0), 'min_samples_leaf': np.float64(3.0), 'min_samples_split': np.float64(9.0)}\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(\n",
    "    fn=objective,\n",
    "    space=space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=10,\n",
    "    trials=trials,\n",
    "    rstate=np.random.default_rng(42)\n",
    ")\n",
    "\n",
    "print(\"Best hyperparameters:\", best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "15d21e4b-ce7c-41f1-9d44-6da926733b90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Mapping index to actual value\n",
    "criterion_list = ['gini', 'entropy']\n",
    "best['criterion'] = criterion_list[best['criterion']]\n",
    "\n",
    "# Cast hyperparameters to int where required\n",
    "best['max_depth'] = int(best['max_depth'])\n",
    "best['min_samples_split'] = int(best['min_samples_split'])\n",
    "best['min_samples_leaf'] = int(best['min_samples_leaf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7027b786-001b-4382-9d37-369c06f395e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the Decision Tree is 0.9130434782608695\n"
     ]
    }
   ],
   "source": [
    "mod_dt = DecisionTreeClassifier(**best, random_state=42)\n",
    "mod_dt.fit(train_X, train_Y)\n",
    "y_pred = mod_dt.predict(test_X)\n",
    "accuracy = metrics.accuracy_score(test_Y, y_pred)\n",
    "\n",
    "print(f\"The accuracy of the Decision Tree is {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "139c6c3a-feb1-4795-97ad-6a924cf28c5c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/18 17:39:06 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "Successfully registered model 'Iris-DT-Classifier'.\n",
      "2025/07/18 17:39:10 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: Iris-DT-Classifier, version 1\n",
      "Created version '1' of model 'Iris-DT-Classifier'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mlflow.models.model.ModelInfo at 0x7f656f1a9ff0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Log model signature\n",
    "signature = infer_signature(train_X, mod_dt.predict(train_X))\n",
    "mlflow.sklearn.log_model(\n",
    "    sk_model=mod_dt, \n",
    "    artifact_path=\"iris_model\",\n",
    "    signature=signature,\n",
    "    input_example=train_X,\n",
    "    registered_model_name=\"Iris-DT-Classifier\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9d80be-fa30-475f-a2ae-3ab26ac30110",
   "metadata": {},
   "source": [
    "## Materialize the feast store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d301a906-93b5-49ca-a32a-844c23440789",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n",
      "Materializing \u001b[1m\u001b[32m1\u001b[0m feature views from \u001b[1m\u001b[32m2025-06-01 00:00:00+00:00\u001b[0m to \u001b[1m\u001b[32m2026-08-01 00:00:00+00:00\u001b[0m into the \u001b[1m\u001b[32msqlite\u001b[0m online store.\n",
      "\n",
      "\u001b[1m\u001b[32miris_features\u001b[0m:\n"
     ]
    }
   ],
   "source": [
    "!cd feast-store/ && feast materialize 2025-06-01T00:00:00 2026-08-01T00:00:00"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92fc018-4928-41f8-a082-ec1daa1602e5",
   "metadata": {},
   "source": [
    "## Make prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c971ecac-eeb0-4cd9-90e5-70dec03d90aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import feast\n",
    "from joblib import load\n",
    "\n",
    "class IrisClassifier:\n",
    "    def __init__(self):\n",
    "        # Load trained model\n",
    "        self.model = load(\"artifacts/model.joblib\")\n",
    "\n",
    "        # Connect to feature store\n",
    "        self.fs = feast.FeatureStore(repo_path=\"feast-store/\")\n",
    "\n",
    "    def predict(self, iris_classes):\n",
    "        # Retrieve online features from Feast\n",
    "        df = pd.read_csv(\"data/iris.csv\", sep=\",\")\n",
    "        features = self.fs.get_online_features(\n",
    "            entity_rows=[{\"sample_id\": sample} for sample in df[\"sample_id\"]],\n",
    "            features=[\n",
    "                \"iris_features:sepal_length\",\n",
    "                \"iris_features:petal_length\",\n",
    "                \"iris_features:sepal_width\",\n",
    "                \"iris_features:petal_width\"\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        df = pd.DataFrame.from_dict(features.to_dict())\n",
    "        print(df)\n",
    "\n",
    "        # Predict species\n",
    "        df[\"predicted_species\"] = self.model.predict(df[sorted(df)])\n",
    "\n",
    "        # Return most frequent predicted species\n",
    "        common_flower_id = df[\"predicted_species\"].mode()[0]\n",
    "        \n",
    "        return common_flower_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "79d682ba-2f84-479b-8112-22d52903ccad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_iris_prediction(): \n",
    "    \n",
    "    model = IrisClassifier()\n",
    "    flowers = data['species'].unique()\n",
    "    # flowers=['setosa', 'virginica', 'versicolor']\n",
    "    common_flower_id = model.predict(flowers)\n",
    "    \n",
    "    print(\"Predicted most common flower species:\", common_flower_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "82af5840-392e-4b45-8b69-b8deed2d7f2f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sample_id  sepal_length  sepal_width  petal_length  petal_width\n",
      "0            0           5.1          3.5           1.4          0.2\n",
      "1            1           4.9          3.0           1.4          0.2\n",
      "2            2           4.7          3.2           1.3          0.2\n",
      "3            3           4.6          3.1           1.5          0.2\n",
      "4            4           5.0          3.6           1.4          0.2\n",
      "..         ...           ...          ...           ...          ...\n",
      "145        145           6.7          3.0           5.2          2.3\n",
      "146        146           6.3          2.5           5.0          1.9\n",
      "147        147           6.5          3.0           5.2          2.0\n",
      "148        148           6.2          3.4           5.4          2.3\n",
      "149        149           5.9          3.0           5.1          1.8\n",
      "\n",
      "[150 rows x 5 columns]\n",
      "Predicted most common flower species: versicolor\n"
     ]
    }
   ],
   "source": [
    "make_iris_prediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a38e1e30-1546-4d48-b23d-8f5efa8e13df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… sanity_test.yaml created in .github/workflows/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "os.makedirs(\".github/workflows\", exist_ok=True)\n",
    "\n",
    "# Define the workflow YAML content\n",
    "workflow_content = \"\"\"name: Sanity Test and Report\n",
    "\n",
    "on:\n",
    "  pull_request:\n",
    "    branches: [main]\n",
    "  workflow_dispatch:\n",
    "\n",
    "permissions:\n",
    "  pull-requests: write\n",
    "  contents: write\n",
    "\n",
    "jobs:\n",
    "  test:\n",
    "    runs-on: ubuntu-latest\n",
    "\n",
    "    steps:\n",
    "      - name: Checkout code\n",
    "        uses: actions/checkout@v4\n",
    "\n",
    "      - name: Set up Python\n",
    "        uses: actions/setup-python@v4\n",
    "        with:\n",
    "          python-version: '3.10'\n",
    "\n",
    "      - name: Install dependencies\n",
    "        run: |\n",
    "          pip install -r requirements.txt\n",
    "\n",
    "      - name: Run model test\n",
    "        run: |\n",
    "          echo \"## Test Results\" >> report.md\n",
    "          python test.py >> report.md 2>&1\n",
    "          echo \"Tests completed on $(date)\" >> report.md\n",
    "\n",
    "      - name: Run training\n",
    "        run: |\n",
    "          python train.py >> report.md 2>&1 || echo \"Training failed with exit code $?\" >> report.md\n",
    "\n",
    "      - name: Setup CML\n",
    "        uses: iterative/setup-cml@v2\n",
    "\n",
    "      - name: Comment report with CML\n",
    "        env:\n",
    "          REPO_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n",
    "        run: |\n",
    "          cml comment create --publish report.md \n",
    "\"\"\"\n",
    "\n",
    "# Write to the YAML file\n",
    "with open(\".github/workflows/sanity_test.yaml\", \"w\") as f:\n",
    "    f.write(workflow_content)\n",
    "\n",
    "print(\"âœ… sanity_test.yaml created in .github/workflows/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c5b380e7-33a9-44f0-831b-e8b001c8cf0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ! git add artifacts/ iris_pipeline.ipynb .github/\n",
    "# ! git commit -m \"Uploaded artifacts and pipeline\"\n",
    "# ! git push origin dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0dc2290-bd57-4044-8285-d62daeabf49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # To pull data from remote repo\n",
    "\n",
    "# git branch --set-upstream-to=origin/dev dev\n",
    "# git pull"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m131",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m131"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
