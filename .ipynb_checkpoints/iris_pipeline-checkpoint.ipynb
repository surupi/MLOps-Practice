{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3c941ef-4344-48e9-a6b7-57f86c5564bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Vertex SDK for Python\n",
    "! pip3 install --upgrade --quiet  google-cloud-aiplatform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7e342cb-39cd-474f-929d-9ffb552127e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BUCKET_URI= f\"gs://temp-mock-oppe-1\" #@param {type:\"string\"} custom\n",
    "PROJECT_ID = \"numeric-poetry-461213-v8\"  # @param {type:\"string\"}\n",
    "LOCATION = \"us-central1\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27532afd-ecd7-4a09-b533-ee7a61d49a06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "\n",
    "aiplatform.init(project=PROJECT_ID, location=LOCATION, staging_bucket=BUCKET_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55bc84b9-eedc-4f35-a6fd-bc1b6a66bd03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# MODEL_ARTIFACT_DIR = \"my-models/iris-classifier-week-3\"  # @param {type:\"string\"}\n",
    "# REPOSITORY = \"iris-classifier-repo\"  # @param {type:\"string\"}\n",
    "# IMAGE = \"iris-classifier-img\"  # @param {type:\"string\"}\n",
    "# MODEL_DISPLAY_NAME = \"iris-classifier\"  # @param {type:\"string\"}\n",
    "# BIGQUERY_DATASET_NAME=\"iris_classifier_tutorial\" #@param {type:\"string\"} custom\n",
    "# AI_PLATFORM_MODEL_NAME=\"iris_classifier_jsd_model\" #@param {type:\"string\"\n",
    "\n",
    "# # Set the defaults if no names were specified\n",
    "# if MODEL_ARTIFACT_DIR == \"[your-artifact-directory]\":\n",
    "#     MODEL_ARTIFACT_DIR = \"custom-container-prediction-model\"\n",
    "\n",
    "# if REPOSITORY == \"[your-repository-name]\":\n",
    "#     REPOSITORY = \"custom-container-prediction\"\n",
    "\n",
    "# if IMAGE == \"[your-image-name]\":\n",
    "#     IMAGE = \"sklearn-fastapi-server\"\n",
    "\n",
    "# if MODEL_DISPLAY_NAME == \"[your-model-display-name]\":\n",
    "#     MODEL_DISPLAY_NAME = \"sklearn-custom-container\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43657cb6-3ec2-4c7d-af7d-86490a7b4de1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "100d532f-8567-4c59-a00b-b47af84b8e55",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "      <th>sample_id</th>\n",
       "      <th>event_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-07-09 14:15:04.253162+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-06-30 14:15:04.255433+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>2</td>\n",
       "      <td>2025-06-24 14:15:04.255778+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>3</td>\n",
       "      <td>2025-07-08 14:15:04.255990+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>4</td>\n",
       "      <td>2025-07-02 14:15:04.256976+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "      <td>145</td>\n",
       "      <td>2025-07-07 14:15:04.286532+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>virginica</td>\n",
       "      <td>146</td>\n",
       "      <td>2025-06-21 14:15:04.286748+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>virginica</td>\n",
       "      <td>147</td>\n",
       "      <td>2025-07-01 14:15:04.286898+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "      <td>148</td>\n",
       "      <td>2025-07-09 14:15:04.287051+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "      <td>149</td>\n",
       "      <td>2025-07-18 14:15:04.287178+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width    species  \\\n",
       "0             5.1          3.5           1.4          0.2     setosa   \n",
       "1             4.9          3.0           1.4          0.2     setosa   \n",
       "2             4.7          3.2           1.3          0.2     setosa   \n",
       "3             4.6          3.1           1.5          0.2     setosa   \n",
       "4             5.0          3.6           1.4          0.2     setosa   \n",
       "..            ...          ...           ...          ...        ...   \n",
       "145           6.7          3.0           5.2          2.3  virginica   \n",
       "146           6.3          2.5           5.0          1.9  virginica   \n",
       "147           6.5          3.0           5.2          2.0  virginica   \n",
       "148           6.2          3.4           5.4          2.3  virginica   \n",
       "149           5.9          3.0           5.1          1.8  virginica   \n",
       "\n",
       "     sample_id                   event_timestamp  \n",
       "0            0  2025-07-09 14:15:04.253162+00:00  \n",
       "1            1  2025-06-30 14:15:04.255433+00:00  \n",
       "2            2  2025-06-24 14:15:04.255778+00:00  \n",
       "3            3  2025-07-08 14:15:04.255990+00:00  \n",
       "4            4  2025-07-02 14:15:04.256976+00:00  \n",
       "..         ...                               ...  \n",
       "145        145  2025-07-07 14:15:04.286532+00:00  \n",
       "146        146  2025-06-21 14:15:04.286748+00:00  \n",
       "147        147  2025-07-01 14:15:04.286898+00:00  \n",
       "148        148  2025-07-09 14:15:04.287051+00:00  \n",
       "149        149  2025-07-18 14:15:04.287178+00:00  \n",
       "\n",
       "[150 rows x 7 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/iris.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dafa7ee6-298b-4199-8603-81dd5e6cb8c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ! git init\n",
    "# ! git remote add origin https://github.com/prashanttnegi/MLOPS-MOCK-OPPE.git\n",
    "# ! git add data/\n",
    "# ! git config --global user.email \"prashant.negi0407@gmail.com\"\n",
    "# ! git config --global user.username \"prashanttnegi\"\n",
    "# ! git branch -M main\n",
    "# ! git commit -m \"Uploaded original iris data\"\n",
    "# ! git push origin main\n",
    "# ! git checkout -b dev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52d34e0-9687-49c4-ad26-49f6edb83efc",
   "metadata": {},
   "source": [
    "## Modifying dataset to upload in bigquery source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b6f9cc7-8fd9-4b74-b439-59bc5eae35cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "\n",
    "df = data.copy()\n",
    "\n",
    "# Add entity and timestamp\n",
    "df[\"sample_id\"] = df.index\n",
    "df[\"event_timestamp\"] = [\n",
    "    pd.to_datetime(datetime.utcnow() - timedelta(days=random.randint(0, 30)), utc=True)\n",
    "    for _ in range(len(df))\n",
    "]\n",
    "\n",
    "data['sample_id'] = data.index\n",
    "data['event_timestamp'] = df['event_timestamp']\n",
    "\n",
    "data.to_csv('data/iris.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e89d5a16-1cec-46b8-ae8a-a7bc5b344f23",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 150 rows to numeric-poetry-461213-v8.mlops_oppe_mock_1.features_table\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "project_id = \"numeric-poetry-461213-v8\"  # replace this\n",
    "dataset_id = \"mlops_oppe_mock_1\"      # create this manually if it doesn't exist\n",
    "table_id = f\"{project_id}.{dataset_id}.features_table\"\n",
    "\n",
    "client = bigquery.Client(project=project_id)\n",
    "\n",
    "# Upload to BigQuery\n",
    "job = client.load_table_from_dataframe(df, table_id)\n",
    "job.result()\n",
    "\n",
    "print(f\"Uploaded {len(df)} rows to {table_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4de8593-dba9-4ad2-8b7d-62678b229b9c",
   "metadata": {},
   "source": [
    "## Introducing feast feature store"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e9298e-c857-430e-96fa-84dfe15c3e2e",
   "metadata": {
    "tags": []
   },
   "source": [
    "! pip install feast[gcp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1bdb920e-57a8-429f-9d58-f689797ae414",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n",
      "/home/jupyter/feast-store/feature_schema.py:6: DeprecationWarning: Entity value_type will be mandatory in the next release. Please specify a value_type for entity 'sample_id'.\n",
      "  sample = Entity(name=\"sample_id\", join_keys=[\"sample_id\"])\n",
      "No project found in the repository. Using project name common_iris defined in feature_store.yaml\n",
      "Applying changes for project common_iris\n",
      "Deploying infrastructure for \u001b[1m\u001b[32miris_features\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! cd feast-store/ && feast apply"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41516d5a-bee3-410f-920b-a8a5b39550b1",
   "metadata": {},
   "source": [
    "## Introducing Hyperopt for Hyperparameter tuning with MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1c225217-80ef-42d3-852e-97ed24cf1aa1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# screen -S \"mlflow_execution\"\n",
    "# pip install mlflow\n",
    "# mflow server --host 0.0.0.0 --port 8100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a463353b-9919-4a55-bd53-6813aca57579",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<Experiment: artifact_location='mlflow-artifacts:/608862416274110921', creation_time=1752848945495, experiment_id='608862416274110921', last_update_time=1752848945495, lifecycle_stage='active', name='IRIS practice classifier: Mlflow Practice', tags={}>, <Experiment: artifact_location='mlflow-artifacts:/0', creation_time=1752848697318, experiment_id='0', last_update_time=1752848697318, lifecycle_stage='active', name='Default', tags={}>]\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "from mlflow import MlflowClient\n",
    "from mlflow.models import infer_signature\n",
    "from pprint import pprint\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:8100\")\n",
    "client = MlflowClient(mlflow.get_tracking_uri())\n",
    "all_experiments = client.search_experiments()\n",
    "print(all_experiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f8295cc4-1a8c-480c-9b7d-3ba9717db20a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/608862416274110921', creation_time=1752848945495, experiment_id='608862416274110921', last_update_time=1752848945495, lifecycle_stage='active', name='IRIS practice classifier: Mlflow Practice', tags={}>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting experiment name for mlflow\n",
    "\n",
    "mlflow.set_experiment(\"IRIS practice classifier: Mlflow Practice\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e976cc0c-67c8-442e-aa77-140d286ee27d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting hyperopt\n",
      "  Downloading hyperopt-0.2.7-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from hyperopt) (2.1.3)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from hyperopt) (1.15.3)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from hyperopt) (1.17.0)\n",
      "Requirement already satisfied: networkx>=2.2 in /opt/conda/lib/python3.10/site-packages (from hyperopt) (3.4.2)\n",
      "Collecting future (from hyperopt)\n",
      "  Downloading future-1.0.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from hyperopt) (4.67.1)\n",
      "Requirement already satisfied: cloudpickle in /opt/conda/lib/python3.10/site-packages (from hyperopt) (3.1.1)\n",
      "Collecting py4j (from hyperopt)\n",
      "  Downloading py4j-0.10.9.9-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Downloading hyperopt-0.2.7-py2.py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading future-1.0.0-py3-none-any.whl (491 kB)\n",
      "Downloading py4j-0.10.9.9-py2.py3-none-any.whl (203 kB)\n",
      "Installing collected packages: py4j, future, hyperopt\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [hyperopt]2/3\u001b[0m [hyperopt]\n",
      "\u001b[1A\u001b[2KSuccessfully installed future-1.0.0 hyperopt-0.2.7 py4j-0.10.9.9\n"
     ]
    }
   ],
   "source": [
    "! pip install hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c0f4d85-5079-494a-9376-07f5f719b219",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from hyperopt import fmin, tpe, hp, Trials, STATUS_OK\n",
    "\n",
    "# Define hyperparameter search space\n",
    "space = {\n",
    "    'criterion': hp.choice('criterion', ['gini', 'entropy']),\n",
    "    'max_depth': hp.quniform('max_depth', 1, 10, 1),\n",
    "    'min_samples_split': hp.quniform('min_samples_split', 2, 10, 1),\n",
    "    'min_samples_leaf': hp.quniform('min_samples_leaf', 1, 5, 1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "14eb4faa-ffc3-40c4-8405-7ecbe4a2fa0c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Feature schema -----\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 7 columns):\n",
      " #   Column           Non-Null Count  Dtype              \n",
      "---  ------           --------------  -----              \n",
      " 0   species          150 non-null    object             \n",
      " 1   sample_id        150 non-null    int64              \n",
      " 2   event_timestamp  150 non-null    datetime64[us, UTC]\n",
      " 3   sepal_length     150 non-null    float64            \n",
      " 4   petal_length     150 non-null    float64            \n",
      " 5   sepal_width      150 non-null    float64            \n",
      " 6   petal_width      150 non-null    float64            \n",
      "dtypes: datetime64[us, UTC](1), float64(4), int64(1), object(1)\n",
      "memory usage: 8.3+ KB\n",
      "None\n",
      "\n",
      "----- Example features -----\n",
      "\n",
      "  species  sample_id                  event_timestamp  sepal_length  \\\n",
      "0  setosa         10 2025-07-13 14:28:39.313390+00:00           5.4   \n",
      "1  setosa         23 2025-06-20 14:28:39.314834+00:00           5.1   \n",
      "2  setosa          3 2025-07-06 14:28:39.311674+00:00           4.6   \n",
      "3  setosa         28 2025-07-10 14:28:39.315217+00:00           5.2   \n",
      "4  setosa         18 2025-07-09 14:28:39.314161+00:00           5.7   \n",
      "\n",
      "   petal_length  sepal_width  petal_width  \n",
      "0           1.5          3.7          0.2  \n",
      "1           1.7          3.3          0.5  \n",
      "2           1.5          3.1          0.2  \n",
      "3           1.4          3.4          0.2  \n",
      "4           1.7          3.8          0.3  \n",
      "   sample_id  sepal_length  petal_length  sepal_width  petal_width\n",
      "0         10           5.4           1.5          3.7          0.2\n",
      "1         23           5.1           1.7          3.3          0.5\n",
      "2          3           4.6           1.5          3.1          0.2\n",
      "3         28           5.2           1.4          3.4          0.2\n",
      "4         18           5.7           1.7          3.8          0.3\n",
      "0    setosa\n",
      "1    setosa\n",
      "2    setosa\n",
      "3    setosa\n",
      "4    setosa\n",
      "Name: species, dtype: object\n",
      "120 120\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['artifacts/model.joblib']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import feast\n",
    "from joblib import dump\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Load Iris entity dataframe (with sample_id and event_timestamp)\n",
    "iris_df = pd.read_csv(\"data/iris.csv\", sep=\",\")\n",
    "iris_df[\"event_timestamp\"] = pd.to_datetime(iris_df[\"event_timestamp\"])\n",
    "iris_df = iris_df.drop(columns=['sepal_length', 'sepal_width', 'petal_width', 'petal_length'])\n",
    "\n",
    "# Connect to feature store\n",
    "fs = feast.FeatureStore(repo_path=\"feast-store/\")\n",
    "\n",
    "# Load features from BigQuery (via Feast)\n",
    "training_df = fs.get_historical_features(\n",
    "    entity_df=iris_df,\n",
    "    features=[\n",
    "        \"iris_features:sepal_length\",\n",
    "        \"iris_features:petal_length\",\n",
    "        \"iris_features:sepal_width\",\n",
    "        \"iris_features:petal_width\"\n",
    "    ],\n",
    ").to_df()\n",
    "\n",
    "print(\"----- Feature schema -----\\n\")\n",
    "print(training_df.info())\n",
    "\n",
    "print(\"\\n----- Example features -----\\n\")\n",
    "print(training_df.head())\n",
    "\n",
    "# Train model\n",
    "target = \"species\"\n",
    "\n",
    "train_X = training_df.drop(columns=[target, 'event_timestamp'])[:120]\n",
    "print(train_X.head())\n",
    "train_Y = training_df.loc[:119, target]\n",
    "print(train_Y.head())\n",
    "print(len(train_X), len(train_Y))\n",
    "\n",
    "# model = LogisticRegression(max_iter=200)\n",
    "model = DecisionTreeClassifier(max_depth = 3, random_state = 1)\n",
    "model.fit(train_X[sorted(train_X.columns)], train_Y)\n",
    "\n",
    "# Save the model\n",
    "dump(model, \"artifacts/model.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5902a8c9-e0e4-4970-a9db-d9dca685c576",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from hyperopt import fmin, tpe, hp, Trials, STATUS_OK\n",
    "\n",
    "# # Define hyperparameter search space\n",
    "# space = {\n",
    "#     'criterion': hp.choice('criterion', ['gini', 'entropy']),\n",
    "#     'max_depth': hp.quniform('max_depth', 1, 10, 1),\n",
    "#     'min_samples_split': hp.quniform('min_samples_split', 2, 10, 1),\n",
    "#     'min_samples_leaf': hp.quniform('min_samples_leaf', 1, 5, 1)\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2d72e153-b499-4abc-85a7-ef4c167e34c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = data.drop(columns=['species', 'sample_id', 'event_timestamp'])\n",
    "Y = data['species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9b9eb793-c8ed-4dde-8369-93a20bff15ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_X, test_X, train_Y, test_Y = train_test_split(X, Y, test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f1bb2c72-b3eb-43e9-beda-942f50816097",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.plotting import parallel_coordinates\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn import metrics\n",
    "\n",
    "# Define the objective function\n",
    "def objective(params):\n",
    "    # Cast hyperparameters to int where required\n",
    "    params['max_depth'] = int(params['max_depth'])\n",
    "    params['min_samples_split'] = int(params['min_samples_split'])\n",
    "    params['min_samples_leaf'] = int(params['min_samples_leaf'])\n",
    "\n",
    "    with mlflow.start_run(nested=True):\n",
    "        \n",
    "        # Log hyperparameters\n",
    "        mlflow.log_params(params)\n",
    "\n",
    "        clf = DecisionTreeClassifier(**params, random_state=42)\n",
    "\n",
    "        clf.fit(train_X, train_Y)\n",
    "\n",
    "        y_pred = clf.predict(test_X)\n",
    "\n",
    "        # Calculate accuracy\n",
    "        accuracy = metrics.accuracy_score(test_Y, y_pred)\n",
    "\n",
    "        # Log metrics\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "\n",
    "        # Log tags\n",
    "        mlflow.set_tag(\"Training Info\", \"DecisionTreeClassifier for Iris Dataset\")\n",
    "\n",
    "        # Log model\n",
    "        mlflow.sklearn.log_model(clf, \"model\")        \n",
    "\n",
    "        return {'loss': 1 - accuracy, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e537b9bd-acaa-4ce7-bfed-9a6e507764cc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/18 14:33:20 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\n",
      "\u001b[31m2025/07/18 14:33:25 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run aged-ant-381 at: http://127.0.0.1:8100/#/experiments/608862416274110921/runs/ca82936656be428ba22a26bf3b79d24a\n",
      "\n",
      "🧪 View experiment at: http://127.0.0.1:8100/#/experiments/608862416274110921\n",
      "\n",
      " 10%|█         | 1/10 [00:05<00:46,  5.12s/trial, best loss: 0.08695652173913049]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/18 14:33:25 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\n",
      "\u001b[31m2025/07/18 14:33:28 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run painted-ant-147 at: http://127.0.0.1:8100/#/experiments/608862416274110921/runs/e8d0675bd7ec4c459464313684a66e36\n",
      "\n",
      "🧪 View experiment at: http://127.0.0.1:8100/#/experiments/608862416274110921    \n",
      "\n",
      " 20%|██        | 2/10 [00:08<00:30,  3.84s/trial, best loss: 0.08695652173913049]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/18 14:33:28 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\n",
      "\u001b[31m2025/07/18 14:33:31 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run suave-shoat-735 at: http://127.0.0.1:8100/#/experiments/608862416274110921/runs/d72bfa85942b4006ad52eff37b9efd27\n",
      "\n",
      "🧪 View experiment at: http://127.0.0.1:8100/#/experiments/608862416274110921    \n",
      "\n",
      " 30%|███       | 3/10 [00:11<00:24,  3.48s/trial, best loss: 0.08695652173913049]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/18 14:33:31 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\n",
      "\u001b[31m2025/07/18 14:33:34 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run peaceful-crane-118 at: http://127.0.0.1:8100/#/experiments/608862416274110921/runs/6ec1798cd34744ec9be72daa77017b03\n",
      "\n",
      "🧪 View experiment at: http://127.0.0.1:8100/#/experiments/608862416274110921    \n",
      "\n",
      " 40%|████      | 4/10 [00:14<00:19,  3.28s/trial, best loss: 0.08695652173913049]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/18 14:33:34 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\n",
      "\u001b[31m2025/07/18 14:33:37 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run dapper-croc-646 at: http://127.0.0.1:8100/#/experiments/608862416274110921/runs/365d5f5ba06540c9bb0716a92dc3d473\n",
      "\n",
      "🧪 View experiment at: http://127.0.0.1:8100/#/experiments/608862416274110921    \n",
      "\n",
      " 50%|█████     | 5/10 [00:17<00:15,  3.16s/trial, best loss: 0.08695652173913049]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/18 14:33:37 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\n",
      "\u001b[31m2025/07/18 14:33:40 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run resilient-cod-631 at: http://127.0.0.1:8100/#/experiments/608862416274110921/runs/cc7e81225b694bd19f65e1acad47f7b9\n",
      "\n",
      "🧪 View experiment at: http://127.0.0.1:8100/#/experiments/608862416274110921    \n",
      "\n",
      " 60%|██████    | 6/10 [00:19<00:12,  3.09s/trial, best loss: 0.08695652173913049]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/18 14:33:40 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\n",
      "\u001b[31m2025/07/18 14:33:43 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run grandiose-shad-474 at: http://127.0.0.1:8100/#/experiments/608862416274110921/runs/e0b4f4d6a5d84c2599c4801fe7170b0d\n",
      "\n",
      "🧪 View experiment at: http://127.0.0.1:8100/#/experiments/608862416274110921    \n",
      "\n",
      " 70%|███████   | 7/10 [00:22<00:09,  3.04s/trial, best loss: 0.08695652173913049]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/18 14:33:43 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\n",
      "\u001b[31m2025/07/18 14:33:46 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run suave-sheep-954 at: http://127.0.0.1:8100/#/experiments/608862416274110921/runs/501c708353944626bc45c18f7d5f489c\n",
      "\n",
      "🧪 View experiment at: http://127.0.0.1:8100/#/experiments/608862416274110921    \n",
      "\n",
      " 80%|████████  | 8/10 [00:25<00:06,  3.03s/trial, best loss: 0.08695652173913049]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/18 14:33:46 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\n",
      "\u001b[31m2025/07/18 14:33:48 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run luminous-cub-878 at: http://127.0.0.1:8100/#/experiments/608862416274110921/runs/b7377d9edb18403d952e55af4dd2089e\n",
      "\n",
      "🧪 View experiment at: http://127.0.0.1:8100/#/experiments/608862416274110921    \n",
      "\n",
      " 90%|█████████ | 9/10 [00:28<00:03,  3.01s/trial, best loss: 0.08695652173913049]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/18 14:33:49 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\n",
      "\u001b[31m2025/07/18 14:33:51 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run casual-stork-430 at: http://127.0.0.1:8100/#/experiments/608862416274110921/runs/e0f75a98e2e64ef49521aa6ea0cabfd5\n",
      "\n",
      "🧪 View experiment at: http://127.0.0.1:8100/#/experiments/608862416274110921    \n",
      "\n",
      "100%|██████████| 10/10 [00:31<00:00,  3.19s/trial, best loss: 0.08695652173913049]\n",
      "Best hyperparameters: {'criterion': np.int64(0), 'max_depth': np.float64(9.0), 'min_samples_leaf': np.float64(3.0), 'min_samples_split': np.float64(9.0)}\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(\n",
    "    fn=objective,\n",
    "    space=space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=10,\n",
    "    trials=trials,\n",
    "    rstate=np.random.default_rng(42)\n",
    ")\n",
    "\n",
    "print(\"Best hyperparameters:\", best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "15d21e4b-ce7c-41f1-9d44-6da926733b90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Mapping index to actual value\n",
    "criterion_list = ['gini', 'entropy']\n",
    "best['criterion'] = criterion_list[best['criterion']]\n",
    "\n",
    "# Cast hyperparameters to int where required\n",
    "best['max_depth'] = int(best['max_depth'])\n",
    "best['min_samples_split'] = int(best['min_samples_split'])\n",
    "best['min_samples_leaf'] = int(best['min_samples_leaf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7027b786-001b-4382-9d37-369c06f395e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the Decision Tree is 0.9130434782608695\n"
     ]
    }
   ],
   "source": [
    "mod_dt = DecisionTreeClassifier(**best, random_state=42)\n",
    "mod_dt.fit(train_X, train_Y)\n",
    "y_pred = mod_dt.predict(test_X)\n",
    "accuracy = metrics.accuracy_score(test_Y, y_pred)\n",
    "\n",
    "print(f\"The accuracy of the Decision Tree is {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "139c6c3a-feb1-4795-97ad-6a924cf28c5c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/18 14:34:46 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "Successfully registered model 'Iris-DT-Classifier'.\n",
      "2025/07/18 14:34:49 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: Iris-DT-Classifier, version 1\n",
      "Created version '1' of model 'Iris-DT-Classifier'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mlflow.models.model.ModelInfo at 0x7f2dd9d915d0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Log model signature\n",
    "signature = infer_signature(train_X, mod_dt.predict(train_X))\n",
    "mlflow.sklearn.log_model(\n",
    "    sk_model=mod_dt, \n",
    "    artifact_path=\"iris_model\",\n",
    "    signature=signature,\n",
    "    input_example=train_X,\n",
    "    registered_model_name=\"Iris-DT-Classifier\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9d80be-fa30-475f-a2ae-3ab26ac30110",
   "metadata": {},
   "source": [
    "## Materialize the feast store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d301a906-93b5-49ca-a32a-844c23440789",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n",
      "Materializing \u001b[1m\u001b[32m1\u001b[0m feature views from \u001b[1m\u001b[32m2025-06-01 00:00:00+00:00\u001b[0m to \u001b[1m\u001b[32m2026-08-01 00:00:00+00:00\u001b[0m into the \u001b[1m\u001b[32msqlite\u001b[0m online store.\n",
      "\n",
      "\u001b[1m\u001b[32miris_features\u001b[0m:\n"
     ]
    }
   ],
   "source": [
    "!cd feast-store/ && feast materialize 2025-06-01T00:00:00 2026-08-01T00:00:00"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92fc018-4928-41f8-a082-ec1daa1602e5",
   "metadata": {},
   "source": [
    "## Make prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c971ecac-eeb0-4cd9-90e5-70dec03d90aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import feast\n",
    "from joblib import load\n",
    "\n",
    "class IrisClassifier:\n",
    "    def __init__(self):\n",
    "        # Load trained model\n",
    "        self.model = load(\"artifacts/model.joblib\")\n",
    "\n",
    "        # Connect to feature store\n",
    "        self.fs = feast.FeatureStore(repo_path=\"feast-store/\")\n",
    "\n",
    "    def predict(self, iris_classes):\n",
    "        # Retrieve online features from Feast\n",
    "        df = pd.read_csv(\"data/iris.csv\", sep=\",\")\n",
    "        features = self.fs.get_online_features(\n",
    "            entity_rows=[{\"sample_id\": sample} for sample in df[\"sample_id\"]],\n",
    "            features=[\n",
    "                \"iris_features:sepal_length\",\n",
    "                \"iris_features:petal_length\",\n",
    "                \"iris_features:sepal_width\",\n",
    "                \"iris_features:petal_width\"\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        df = pd.DataFrame.from_dict(features.to_dict())\n",
    "        print(df)\n",
    "\n",
    "        # Predict species\n",
    "        df[\"predicted_species\"] = self.model.predict(df[sorted(df)])\n",
    "\n",
    "        # Return most frequent predicted species\n",
    "        common_flower_id = df[\"predicted_species\"].mode()[0]\n",
    "        \n",
    "        return common_flower_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "79d682ba-2f84-479b-8112-22d52903ccad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_iris_prediction(): \n",
    "    \n",
    "    model = IrisClassifier()\n",
    "    flowers = data['species'].unique()\n",
    "    # flowers=['setosa', 'virginica', 'versicolor']\n",
    "    common_flower_id = model.predict(flowers)\n",
    "    \n",
    "    print(\"Predicted most common flower species:\", common_flower_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "82af5840-392e-4b45-8b69-b8deed2d7f2f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sample_id  sepal_length  sepal_width  petal_width  petal_length\n",
      "0            0           5.1          3.5          0.2           1.4\n",
      "1            1           4.9          3.0          0.2           1.4\n",
      "2            2           4.7          3.2          0.2           1.3\n",
      "3            3           4.6          3.1          0.2           1.5\n",
      "4            4           5.0          3.6          0.2           1.4\n",
      "..         ...           ...          ...          ...           ...\n",
      "145        145           6.7          3.0          2.3           5.2\n",
      "146        146           6.3          2.5          1.9           5.0\n",
      "147        147           6.5          3.0          2.0           5.2\n",
      "148        148           6.2          3.4          2.3           5.4\n",
      "149        149           5.9          3.0          1.8           5.1\n",
      "\n",
      "[150 rows x 5 columns]\n",
      "Predicted most common flower species: versicolor\n"
     ]
    }
   ],
   "source": [
    "make_iris_prediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "a38e1e30-1546-4d48-b23d-8f5efa8e13df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ sanity_test.yaml created in .github/workflows/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "os.makedirs(\".github/workflows\", exist_ok=True)\n",
    "\n",
    "# Define the workflow YAML content\n",
    "workflow_content = \"\"\"name: Sanity Test and Report\n",
    "\n",
    "on:\n",
    "  pull_request:\n",
    "    branches: [main]\n",
    "  workflow_dispatch:\n",
    "\n",
    "permissions:\n",
    "  pull-requests: write\n",
    "  contents: write\n",
    "\n",
    "jobs:\n",
    "  test:\n",
    "    runs-on: ubuntu-latest\n",
    "\n",
    "    steps:\n",
    "      - name: Checkout code\n",
    "        uses: actions/checkout@v4\n",
    "\n",
    "      - name: Set up Python\n",
    "        uses: actions/setup-python@v4\n",
    "        with:\n",
    "          python-version: '3.10'\n",
    "\n",
    "      - name: Install dependencies\n",
    "        run: |\n",
    "          pip install -r requirements.txt\n",
    "\n",
    "      - name: Run model test\n",
    "        run: |\n",
    "          echo \"## Test Results\" >> report.md\n",
    "          python test.py >> report.md 2>&1\n",
    "          echo \"Tests completed on $(date)\" >> report.md\n",
    "\n",
    "      - name: Run training\n",
    "        run: |\n",
    "          python train.py >> report.md 2>&1 || echo \"Training failed with exit code $?\" >> report.md\n",
    "\n",
    "      - name: Setup CML\n",
    "        uses: iterative/setup-cml@v2\n",
    "\n",
    "      - name: Comment report with CML\n",
    "        env:\n",
    "          REPO_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n",
    "        run: |\n",
    "          cml comment create --publish report.md \n",
    "\"\"\"\n",
    "\n",
    "# Write to the YAML file\n",
    "with open(\".github/workflows/sanity_test.yaml\", \"w\") as f:\n",
    "    f.write(workflow_content)\n",
    "\n",
    "print(\"✅ sanity_test.yaml created in .github/workflows/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c5b380e7-33a9-44f0-831b-e8b001c8cf0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ! git add artifacts/ iris_pipeline.ipynb .github/\n",
    "# ! git commit -m \"Uploaded artifacts and pipeline\"\n",
    "# ! git push origin dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0dc2290-bd57-4044-8285-d62daeabf49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # To pull data from remote repo\n",
    "\n",
    "# git branch --set-upstream-to=origin/dev dev\n",
    "# git pull"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m131",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m131"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
